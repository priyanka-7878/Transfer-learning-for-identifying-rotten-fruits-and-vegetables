{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 26646,
     "status": "ok",
     "timestamp": 1751009022951,
     "user": {
      "displayName": "Subhash Annapareddy",
      "userId": "08523036654293280325"
     },
     "user_tz": -330
    },
    "id": "-Yr60eaZRNk-",
    "outputId": "e9fbaf46-d730-4dc5-aa66-a9f93ff4bad3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting roboflow\n",
      "  Downloading roboflow-1.1.66-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from roboflow) (2025.6.15)\n",
      "Collecting idna==3.7 (from roboflow)\n",
      "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: cycler in /usr/local/lib/python3.11/dist-packages (from roboflow) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.4.8)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from roboflow) (3.10.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.0.2)\n",
      "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
      "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from roboflow) (11.2.1)\n",
      "Collecting pillow-heif>=0.18.0 (from roboflow)\n",
      "  Downloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.9.0.post0)\n",
      "Collecting python-dotenv (from roboflow)\n",
      "  Downloading python_dotenv-1.1.1-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.32.3)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.17.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.4.0)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (6.0.2)\n",
      "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.0.0)\n",
      "Collecting filetype (from roboflow)\n",
      "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (1.3.2)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (4.58.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (24.2)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (3.2.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->roboflow) (3.4.2)\n",
      "Downloading roboflow-1.1.66-py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m16.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
      "Downloading python_dotenv-1.1.1-py3-none-any.whl (20 kB)\n",
      "Installing collected packages: filetype, python-dotenv, pillow-heif, opencv-python-headless, idna, roboflow\n",
      "  Attempting uninstall: opencv-python-headless\n",
      "    Found existing installation: opencv-python-headless 4.11.0.86\n",
      "    Uninstalling opencv-python-headless-4.11.0.86:\n",
      "      Successfully uninstalled opencv-python-headless-4.11.0.86\n",
      "  Attempting uninstall: idna\n",
      "    Found existing installation: idna 3.10\n",
      "    Uninstalling idna-3.10:\n",
      "      Successfully uninstalled idna-3.10\n",
      "Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pillow-heif-0.22.0 python-dotenv-1.1.1 roboflow-1.1.66\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "d42d77565fa640709ab9d448efe3f79f",
       "pip_warning": {
        "packages": [
         "cv2",
         "idna"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading Dataset Version Zip in ripescan-2-1 to folder:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 10739/10739 [00:01<00:00, 7149.81it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Dataset Version Zip to ripescan-2-1 in folder:: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1347/1347 [00:00<00:00, 9040.50it/s]\n"
     ]
    }
   ],
   "source": [
    "# STEP 1: Install Required Libraries\n",
    "!pip install roboflow gradio pillow_heif==0.11.1 --quiet\n",
    "\n",
    "# STEP 2: Download Dataset using Roboflow\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"ljOV2xnWYPwLbinaMbIv\")\n",
    "project = rf.workspace(\"fakharsworkspace\").project(\"ripescan-2\")\n",
    "version = project.version(1)\n",
    "dataset = version.download(\"folder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 5552893,
     "status": "ok",
     "timestamp": 1751021219510,
     "user": {
      "displayName": "Subhash Annapareddy",
      "userId": "08523036654293280325"
     },
     "user_tz": -330
    },
    "id": "nEIZ2qtbCcJm",
    "outputId": "ad74dd42-1f2b-4df6-8a70-082023dd327c"
   },
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.13.3' requires the ipykernel package.\n",
      "\u001b[1;31m<a href='command:jupyter.createPythonEnvAndSelectController'>Create a Python Environment</a> with the required packages."
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import seaborn as sns\n",
    "import gradio as gr\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "# Set paths\n",
    "train_path = \"/content/ripescan-2-1/train\"\n",
    "test_path = \"/content/ripescan-2-1/test\"\n",
    "validation_path = \"/content/ripescan-2-1/valid\"\n",
    "\n",
    "# Load sample image\n",
    "def load_sample_image(path):\n",
    "    for category in os.listdir(path):\n",
    "        category_path = os.path.join(path, category)\n",
    "        image_path = os.path.join(category_path, os.listdir(category_path)[0])\n",
    "        img = cv2.imread(image_path)\n",
    "        img = cv2.resize(img, (224, 224))\n",
    "        return img\n",
    "fig = px.imshow(load_sample_image(train_path))\n",
    "fig.update_layout(title=\"Sample Image from Training Set\")\n",
    "fig.show()\n",
    "\n",
    "# Data generators\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=40, width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2, shear_range=0.2, zoom_range=0.2,\n",
    "                                   horizontal_flip=True, fill_mode='nearest')\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_path, target_size=(224, 224),\n",
    "                                                    batch_size=32, class_mode='categorical')\n",
    "validation_generator = test_datagen.flow_from_directory(validation_path, target_size=(224, 224),\n",
    "                                                        batch_size=32, class_mode='categorical')\n",
    "test_generator = test_datagen.flow_from_directory(test_path, target_size=(224, 224),\n",
    "                                                  batch_size=32, class_mode='categorical', shuffle=False)\n",
    "\n",
    "# Build VGG16 model\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "base_model.trainable = False\n",
    "\n",
    "model = Sequential([\n",
    "    base_model,\n",
    "    Flatten(),\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(len(train_generator.class_indices), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(train_generator, epochs=3, validation_data=validation_generator)\n",
    "\n",
    "# Fine-tune model\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[:15]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=1e-5), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history_fine = model.fit(train_generator, epochs=10, validation_data=validation_generator)\n",
    "\n",
    "# Evaluate model\n",
    "loss, accuracy = model.evaluate(test_generator)\n",
    "print(f\"Test Accuracy: {accuracy*100:.2f}%\")\n",
    "\n",
    "# Classification report\n",
    "Y_pred = model.predict(test_generator)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(test_generator.classes, y_pred, target_names=test_generator.class_indices.keys()))\n",
    "\n",
    "# Confusion matrix\n",
    "cm = confusion_matrix(test_generator.classes, y_pred)\n",
    "cm_fig = px.imshow(cm, labels=dict(x=\"Predicted\", y=\"True\", color=\"Count\"),\n",
    "                   x=list(test_generator.class_indices.keys()),\n",
    "                   y=list(test_generator.class_indices.keys()), text_auto=True)\n",
    "cm_fig.update_layout(title=\"Confusion Matrix\")\n",
    "cm_fig.show()\n",
    "\n",
    "# Accuracy plot\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(y=history.history['accuracy'], mode='lines', name='Train Accuracy'))\n",
    "fig.add_trace(go.Scatter(y=history.history['val_accuracy'], mode='lines', name='Validation Accuracy'))\n",
    "fig.update_layout(title='Model Accuracy', xaxis_title='Epoch', yaxis_title='Accuracy')\n",
    "fig.show()\n",
    "\n",
    "# Loss plot\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(y=history.history['loss'], mode='lines', name='Train Loss'))\n",
    "fig.add_trace(go.Scatter(y=history.history['val_loss'], mode='lines', name='Validation Loss'))\n",
    "fig.update_layout(title='Model Loss', xaxis_title='Epoch', yaxis_title='Loss')\n",
    "fig.show()\n",
    "\n",
    "# Fine-tuning Accuracy plot\n",
    "fig_fine = go.Figure()\n",
    "fig_fine.add_trace(go.Scatter(y=history_fine.history['accuracy'], mode='lines', name='Fine-tune Train Accuracy'))\n",
    "fig_fine.add_trace(go.Scatter(y=history_fine.history['val_accuracy'], mode='lines', name='Fine-tune Validation Accuracy'))\n",
    "fig_fine.update_layout(title='Fine-tuning Accuracy', xaxis_title='Epoch', yaxis_title='Accuracy')\n",
    "fig_fine.show()\n",
    "\n",
    "# Fine-tuning Loss plot\n",
    "fig_fine_loss = go.Figure()\n",
    "fig_fine_loss.add_trace(go.Scatter(y=history_fine.history['loss'], mode='lines', name='Fine-tune Train Loss'))\n",
    "fig_fine_loss.add_trace(go.Scatter(y=history_fine.history['val_loss'], mode='lines', name='Fine-tune Validation Loss'))\n",
    "fig_fine_loss.update_layout(title='Fine-tuning Loss', xaxis_title='Epoch', yaxis_title='Loss')\n",
    "fig_fine_loss.show()\n",
    "\n",
    "# Save model\n",
    "model.save('/kaggle/working/fruit_veg_classifier.h5')\n",
    "\n",
    "# Gradio Interface\n",
    "class_names = list(test_generator.class_indices.keys())\n",
    "\n",
    "def classify_fruit_veg(img):\n",
    "    img = img.resize((224, 224))\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array = img_array / 255.0\n",
    "    predictions = model.predict(img_array)[0]\n",
    "    top_index = np.argmax(predictions)\n",
    "    confidence = predictions[top_index]\n",
    "    predicted_label = class_names[top_index]\n",
    "    return f\"Prediction: {predicted_label} ({confidence * 100:.2f}%)\"\n",
    "\n",
    "interface = gr.Interface(\n",
    "    fn=classify_fruit_veg,\n",
    "    inputs=gr.Image(type=\"pil\", label=\"Upload Fruit or Vegetable Image\"),\n",
    "    outputs=\"text\",\n",
    "    title=\"ğŸğŸ¥¦ Smart Sorting Classifier\",\n",
    "    description=\"Upload an image of a fruit or vegetable(EX:Banana,Mango,Tomato). The model will predict the class using transfer learning (VGG16).\"\n",
    ")\n",
    "\n",
    "interface.launch(share=True)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOnG31fYL/SrX092GHcJ8LQ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0

}
